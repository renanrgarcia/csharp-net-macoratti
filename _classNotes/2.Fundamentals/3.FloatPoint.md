# Floating Point Numbers

- `float`: 32-bit single-precision floating-point number. Range: ±1.5 × 10^−45 to ±3.4 × 10^38. .NET type: `System.Single`.
- `double`: 64-bit double-precision floating-point number. Range: ±5.0 × 10^−324 to ±1.7 × 10^308. .NET type: `System.Double`.
- `decimal`: 128-bit precise decimal value with 28-29 significant digits. Range: ±1.0 × 10^−28 to ±7.9 × 10^28. .NET type: `System.Decimal`. It is used for financial and monetary calculations where precision is critical.

- Represents real numbers with a fractional part.
- Default value: 0.0.
- `float` and `double` are used for scientific calculations, while `decimal` is used for financial calculations.
- We can initialize floating-point numbers using the `f` or `F` suffix for `float`, and the `d` or `D` suffix for `double`. The `m` or `M` suffix is used for `decimal`.
  - But `double` is the default type for floating-point literals in C#. So, if we write `3.14`, it will be treated as a `double` unless we specify otherwise.
